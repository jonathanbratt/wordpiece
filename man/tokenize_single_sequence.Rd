% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tokenization.R
\name{tokenize_single_sequence}
\alias{tokenize_single_sequence}
\title{Tokenize Sequence with Word Pieces}
\usage{
tokenize_single_sequence(text, vocab, unk_token = "[UNK]", max_chars = 100)
}
\arguments{
\item{text}{Character scalar; text to tokenize.}

\item{vocab}{The word piece vocabulary to use.}

\item{unk_token}{Token to represent unknown words.}

\item{max_chars}{Maximum length of word recognized.}
}
\value{
An named integer vector, giving the tokenization of the input
  sequence. The integers values are the token ids, and the names are the
  tokens.
}
\description{
Given a single sequence of text and a wordpiece vocabulary, tokenizes the
text.
}
\examples{
\dontrun{
vocab <- load_vocab("path/to/vocab.txt")
tokens <- tokenize_single_sequence(
  text = "I love tacos!",
  vocab = vocab
)
}
}
